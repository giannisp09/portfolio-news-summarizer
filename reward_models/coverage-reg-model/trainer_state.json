{
  "best_global_step": 15000,
  "best_metric": 0.017234506085515022,
  "best_model_checkpoint": "reward_model/checkpoint-15000",
  "epoch": 0.12059719732113426,
  "eval_steps": 1000,
  "global_step": 15000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008039813154742284,
      "grad_norm": 8.428757667541504,
      "learning_rate": 4.9992040584976804e-05,
      "loss": 0.0729,
      "step": 100
    },
    {
      "epoch": 0.0016079626309484568,
      "grad_norm": 7.374626159667969,
      "learning_rate": 4.998400077182207e-05,
      "loss": 0.0476,
      "step": 200
    },
    {
      "epoch": 0.002411943946422685,
      "grad_norm": 2.38647723197937,
      "learning_rate": 4.9975960958667324e-05,
      "loss": 0.0694,
      "step": 300
    },
    {
      "epoch": 0.0032159252618969136,
      "grad_norm": 2.386453628540039,
      "learning_rate": 4.996792114551258e-05,
      "loss": 0.0628,
      "step": 400
    },
    {
      "epoch": 0.0040199065773711415,
      "grad_norm": 4.550052165985107,
      "learning_rate": 4.9959881332357836e-05,
      "loss": 0.0526,
      "step": 500
    },
    {
      "epoch": 0.00482388789284537,
      "grad_norm": 3.6150922775268555,
      "learning_rate": 4.99518415192031e-05,
      "loss": 0.0612,
      "step": 600
    },
    {
      "epoch": 0.005627869208319598,
      "grad_norm": 1.3253222703933716,
      "learning_rate": 4.9943801706048356e-05,
      "loss": 0.0468,
      "step": 700
    },
    {
      "epoch": 0.006431850523793827,
      "grad_norm": 4.319876670837402,
      "learning_rate": 4.993576189289361e-05,
      "loss": 0.0584,
      "step": 800
    },
    {
      "epoch": 0.007235831839268055,
      "grad_norm": 2.716306686401367,
      "learning_rate": 4.992772207973887e-05,
      "loss": 0.0516,
      "step": 900
    },
    {
      "epoch": 0.008039813154742283,
      "grad_norm": 12.602311134338379,
      "learning_rate": 4.9919682266584125e-05,
      "loss": 0.0461,
      "step": 1000
    },
    {
      "epoch": 0.008039813154742283,
      "eval_loss": 0.07524643838405609,
      "eval_mse": 0.07524643838405609,
      "eval_runtime": 760.917,
      "eval_samples_per_second": 143.067,
      "eval_steps_per_second": 17.884,
      "step": 1000
    },
    {
      "epoch": 0.008843794470216512,
      "grad_norm": 7.191272735595703,
      "learning_rate": 4.991164245342939e-05,
      "loss": 0.0565,
      "step": 1100
    },
    {
      "epoch": 0.00964777578569074,
      "grad_norm": 7.014795303344727,
      "learning_rate": 4.9903602640274644e-05,
      "loss": 0.047,
      "step": 1200
    },
    {
      "epoch": 0.01045175710116497,
      "grad_norm": 3.6931369304656982,
      "learning_rate": 4.98955628271199e-05,
      "loss": 0.0463,
      "step": 1300
    },
    {
      "epoch": 0.011255738416639197,
      "grad_norm": 1.1730576753616333,
      "learning_rate": 4.988752301396516e-05,
      "loss": 0.0426,
      "step": 1400
    },
    {
      "epoch": 0.012059719732113425,
      "grad_norm": 2.458869457244873,
      "learning_rate": 4.987948320081042e-05,
      "loss": 0.0485,
      "step": 1500
    },
    {
      "epoch": 0.012863701047587654,
      "grad_norm": 6.114049911499023,
      "learning_rate": 4.9871443387655676e-05,
      "loss": 0.041,
      "step": 1600
    },
    {
      "epoch": 0.013667682363061883,
      "grad_norm": 1.7576689720153809,
      "learning_rate": 4.986340357450093e-05,
      "loss": 0.0452,
      "step": 1700
    },
    {
      "epoch": 0.01447166367853611,
      "grad_norm": 3.9022772312164307,
      "learning_rate": 4.985536376134619e-05,
      "loss": 0.0386,
      "step": 1800
    },
    {
      "epoch": 0.015275644994010339,
      "grad_norm": 1.8014177083969116,
      "learning_rate": 4.984732394819145e-05,
      "loss": 0.0407,
      "step": 1900
    },
    {
      "epoch": 0.016079626309484566,
      "grad_norm": 2.253187417984009,
      "learning_rate": 4.983928413503671e-05,
      "loss": 0.0454,
      "step": 2000
    },
    {
      "epoch": 0.016079626309484566,
      "eval_loss": 0.02772912010550499,
      "eval_mse": 0.02772912010550499,
      "eval_runtime": 762.7696,
      "eval_samples_per_second": 142.719,
      "eval_steps_per_second": 17.84,
      "step": 2000
    },
    {
      "epoch": 0.016883607624958795,
      "grad_norm": 1.3495960235595703,
      "learning_rate": 4.983124432188196e-05,
      "loss": 0.0359,
      "step": 2100
    },
    {
      "epoch": 0.017687588940433024,
      "grad_norm": 1.8870030641555786,
      "learning_rate": 4.9823204508727214e-05,
      "loss": 0.0369,
      "step": 2200
    },
    {
      "epoch": 0.018491570255907253,
      "grad_norm": 2.336045980453491,
      "learning_rate": 4.981516469557248e-05,
      "loss": 0.0463,
      "step": 2300
    },
    {
      "epoch": 0.01929555157138148,
      "grad_norm": 4.538466453552246,
      "learning_rate": 4.9807124882417734e-05,
      "loss": 0.0354,
      "step": 2400
    },
    {
      "epoch": 0.02009953288685571,
      "grad_norm": 1.4100099802017212,
      "learning_rate": 4.979908506926299e-05,
      "loss": 0.0365,
      "step": 2500
    },
    {
      "epoch": 0.02090351420232994,
      "grad_norm": 6.381231307983398,
      "learning_rate": 4.9791045256108246e-05,
      "loss": 0.0286,
      "step": 2600
    },
    {
      "epoch": 0.021707495517804168,
      "grad_norm": 5.848573207855225,
      "learning_rate": 4.978300544295351e-05,
      "loss": 0.0424,
      "step": 2700
    },
    {
      "epoch": 0.022511476833278393,
      "grad_norm": 5.837521076202393,
      "learning_rate": 4.9774965629798766e-05,
      "loss": 0.035,
      "step": 2800
    },
    {
      "epoch": 0.023315458148752622,
      "grad_norm": 1.6897304058074951,
      "learning_rate": 4.976692581664402e-05,
      "loss": 0.0297,
      "step": 2900
    },
    {
      "epoch": 0.02411943946422685,
      "grad_norm": 1.365207552909851,
      "learning_rate": 4.975888600348928e-05,
      "loss": 0.0302,
      "step": 3000
    },
    {
      "epoch": 0.02411943946422685,
      "eval_loss": 0.023232225328683853,
      "eval_mse": 0.023232225328683853,
      "eval_runtime": 761.8775,
      "eval_samples_per_second": 142.886,
      "eval_steps_per_second": 17.861,
      "step": 3000
    },
    {
      "epoch": 0.02492342077970108,
      "grad_norm": 1.6279882192611694,
      "learning_rate": 4.9750846190334535e-05,
      "loss": 0.0375,
      "step": 3100
    },
    {
      "epoch": 0.02572740209517531,
      "grad_norm": 4.1959614753723145,
      "learning_rate": 4.97428063771798e-05,
      "loss": 0.031,
      "step": 3200
    },
    {
      "epoch": 0.026531383410649537,
      "grad_norm": 0.9224878549575806,
      "learning_rate": 4.9734766564025054e-05,
      "loss": 0.0408,
      "step": 3300
    },
    {
      "epoch": 0.027335364726123766,
      "grad_norm": 5.315622329711914,
      "learning_rate": 4.972672675087031e-05,
      "loss": 0.0305,
      "step": 3400
    },
    {
      "epoch": 0.028139346041597995,
      "grad_norm": 2.7844839096069336,
      "learning_rate": 4.971868693771557e-05,
      "loss": 0.029,
      "step": 3500
    },
    {
      "epoch": 0.02894332735707222,
      "grad_norm": 0.9122578501701355,
      "learning_rate": 4.971064712456083e-05,
      "loss": 0.036,
      "step": 3600
    },
    {
      "epoch": 0.02974730867254645,
      "grad_norm": 3.632812023162842,
      "learning_rate": 4.9702607311406086e-05,
      "loss": 0.0318,
      "step": 3700
    },
    {
      "epoch": 0.030551289988020678,
      "grad_norm": 4.75166654586792,
      "learning_rate": 4.969456749825134e-05,
      "loss": 0.035,
      "step": 3800
    },
    {
      "epoch": 0.03135527130349491,
      "grad_norm": 2.3209433555603027,
      "learning_rate": 4.96865276850966e-05,
      "loss": 0.0417,
      "step": 3900
    },
    {
      "epoch": 0.03215925261896913,
      "grad_norm": 3.0178897380828857,
      "learning_rate": 4.967848787194186e-05,
      "loss": 0.0268,
      "step": 4000
    },
    {
      "epoch": 0.03215925261896913,
      "eval_loss": 0.04780544340610504,
      "eval_mse": 0.04780544340610504,
      "eval_runtime": 762.9409,
      "eval_samples_per_second": 142.687,
      "eval_steps_per_second": 17.836,
      "step": 4000
    },
    {
      "epoch": 0.032963233934443364,
      "grad_norm": 2.3936760425567627,
      "learning_rate": 4.967044805878712e-05,
      "loss": 0.03,
      "step": 4100
    },
    {
      "epoch": 0.03376721524991759,
      "grad_norm": 0.9669892191886902,
      "learning_rate": 4.9662408245632375e-05,
      "loss": 0.0318,
      "step": 4200
    },
    {
      "epoch": 0.03457119656539182,
      "grad_norm": 0.32925549149513245,
      "learning_rate": 4.965436843247763e-05,
      "loss": 0.0265,
      "step": 4300
    },
    {
      "epoch": 0.03537517788086605,
      "grad_norm": 1.3706108331680298,
      "learning_rate": 4.964632861932289e-05,
      "loss": 0.0253,
      "step": 4400
    },
    {
      "epoch": 0.03617915919634028,
      "grad_norm": 2.499797821044922,
      "learning_rate": 4.963828880616815e-05,
      "loss": 0.03,
      "step": 4500
    },
    {
      "epoch": 0.036983140511814505,
      "grad_norm": 4.40493631362915,
      "learning_rate": 4.9630248993013407e-05,
      "loss": 0.0318,
      "step": 4600
    },
    {
      "epoch": 0.03778712182728873,
      "grad_norm": 1.06895112991333,
      "learning_rate": 4.962220917985866e-05,
      "loss": 0.0346,
      "step": 4700
    },
    {
      "epoch": 0.03859110314276296,
      "grad_norm": 1.3402080535888672,
      "learning_rate": 4.961416936670392e-05,
      "loss": 0.0298,
      "step": 4800
    },
    {
      "epoch": 0.03939508445823719,
      "grad_norm": 2.6916141510009766,
      "learning_rate": 4.960612955354918e-05,
      "loss": 0.0395,
      "step": 4900
    },
    {
      "epoch": 0.04019906577371142,
      "grad_norm": 4.864893436431885,
      "learning_rate": 4.959808974039444e-05,
      "loss": 0.0276,
      "step": 5000
    },
    {
      "epoch": 0.04019906577371142,
      "eval_loss": 0.020182890817523003,
      "eval_mse": 0.020182890817523003,
      "eval_runtime": 761.8706,
      "eval_samples_per_second": 142.888,
      "eval_steps_per_second": 17.861,
      "step": 5000
    },
    {
      "epoch": 0.041003047089185646,
      "grad_norm": 0.8378413319587708,
      "learning_rate": 4.9590049927239695e-05,
      "loss": 0.0271,
      "step": 5100
    },
    {
      "epoch": 0.04180702840465988,
      "grad_norm": 3.824697494506836,
      "learning_rate": 4.958201011408495e-05,
      "loss": 0.0305,
      "step": 5200
    },
    {
      "epoch": 0.0426110097201341,
      "grad_norm": 0.5897384285926819,
      "learning_rate": 4.9573970300930214e-05,
      "loss": 0.0354,
      "step": 5300
    },
    {
      "epoch": 0.043414991035608336,
      "grad_norm": 1.5249383449554443,
      "learning_rate": 4.9565930487775464e-05,
      "loss": 0.0278,
      "step": 5400
    },
    {
      "epoch": 0.04421897235108256,
      "grad_norm": 0.5445265769958496,
      "learning_rate": 4.955789067462072e-05,
      "loss": 0.0399,
      "step": 5500
    },
    {
      "epoch": 0.045022953666556786,
      "grad_norm": 1.1062934398651123,
      "learning_rate": 4.954985086146598e-05,
      "loss": 0.0282,
      "step": 5600
    },
    {
      "epoch": 0.04582693498203102,
      "grad_norm": 1.3372302055358887,
      "learning_rate": 4.954181104831124e-05,
      "loss": 0.0291,
      "step": 5700
    },
    {
      "epoch": 0.046630916297505244,
      "grad_norm": 2.4114129543304443,
      "learning_rate": 4.9533771235156496e-05,
      "loss": 0.0285,
      "step": 5800
    },
    {
      "epoch": 0.047434897612979476,
      "grad_norm": 3.564701557159424,
      "learning_rate": 4.952573142200175e-05,
      "loss": 0.0335,
      "step": 5900
    },
    {
      "epoch": 0.0482388789284537,
      "grad_norm": 3.5471396446228027,
      "learning_rate": 4.951769160884701e-05,
      "loss": 0.0374,
      "step": 6000
    },
    {
      "epoch": 0.0482388789284537,
      "eval_loss": 0.026041600853204727,
      "eval_mse": 0.026041600853204727,
      "eval_runtime": 763.3255,
      "eval_samples_per_second": 142.615,
      "eval_steps_per_second": 17.827,
      "step": 6000
    },
    {
      "epoch": 0.049042860243927934,
      "grad_norm": 3.100247621536255,
      "learning_rate": 4.950965179569227e-05,
      "loss": 0.0317,
      "step": 6100
    },
    {
      "epoch": 0.04984684155940216,
      "grad_norm": 3.200993776321411,
      "learning_rate": 4.950161198253753e-05,
      "loss": 0.0298,
      "step": 6200
    },
    {
      "epoch": 0.050650822874876385,
      "grad_norm": 1.4738941192626953,
      "learning_rate": 4.9493572169382784e-05,
      "loss": 0.0258,
      "step": 6300
    },
    {
      "epoch": 0.05145480419035062,
      "grad_norm": 2.310606002807617,
      "learning_rate": 4.948553235622804e-05,
      "loss": 0.0286,
      "step": 6400
    },
    {
      "epoch": 0.05225878550582484,
      "grad_norm": 3.508796453475952,
      "learning_rate": 4.9477492543073304e-05,
      "loss": 0.0284,
      "step": 6500
    },
    {
      "epoch": 0.053062766821299075,
      "grad_norm": 3.731604814529419,
      "learning_rate": 4.946945272991856e-05,
      "loss": 0.0257,
      "step": 6600
    },
    {
      "epoch": 0.0538667481367733,
      "grad_norm": 3.032884359359741,
      "learning_rate": 4.9461412916763817e-05,
      "loss": 0.0293,
      "step": 6700
    },
    {
      "epoch": 0.05467072945224753,
      "grad_norm": 2.7885966300964355,
      "learning_rate": 4.945337310360907e-05,
      "loss": 0.0285,
      "step": 6800
    },
    {
      "epoch": 0.05547471076772176,
      "grad_norm": 2.293332576751709,
      "learning_rate": 4.944533329045433e-05,
      "loss": 0.0303,
      "step": 6900
    },
    {
      "epoch": 0.05627869208319599,
      "grad_norm": 1.6156728267669678,
      "learning_rate": 4.943729347729959e-05,
      "loss": 0.0282,
      "step": 7000
    },
    {
      "epoch": 0.05627869208319599,
      "eval_loss": 0.061749786138534546,
      "eval_mse": 0.061749786138534546,
      "eval_runtime": 762.8648,
      "eval_samples_per_second": 142.702,
      "eval_steps_per_second": 17.838,
      "step": 7000
    },
    {
      "epoch": 0.057082673398670215,
      "grad_norm": 4.5299458503723145,
      "learning_rate": 4.942925366414485e-05,
      "loss": 0.0271,
      "step": 7100
    },
    {
      "epoch": 0.05788665471414444,
      "grad_norm": 1.3641527891159058,
      "learning_rate": 4.9421213850990105e-05,
      "loss": 0.0275,
      "step": 7200
    },
    {
      "epoch": 0.05869063602961867,
      "grad_norm": 3.8168365955352783,
      "learning_rate": 4.941317403783536e-05,
      "loss": 0.0287,
      "step": 7300
    },
    {
      "epoch": 0.0594946173450929,
      "grad_norm": 0.5800448060035706,
      "learning_rate": 4.9405134224680624e-05,
      "loss": 0.0308,
      "step": 7400
    },
    {
      "epoch": 0.06029859866056713,
      "grad_norm": 1.2533656358718872,
      "learning_rate": 4.939709441152588e-05,
      "loss": 0.0356,
      "step": 7500
    },
    {
      "epoch": 0.061102579976041356,
      "grad_norm": 2.0559611320495605,
      "learning_rate": 4.938905459837114e-05,
      "loss": 0.031,
      "step": 7600
    },
    {
      "epoch": 0.06190656129151559,
      "grad_norm": 0.4812319278717041,
      "learning_rate": 4.938101478521639e-05,
      "loss": 0.0283,
      "step": 7700
    },
    {
      "epoch": 0.06271054260698981,
      "grad_norm": 1.3752256631851196,
      "learning_rate": 4.937297497206165e-05,
      "loss": 0.0243,
      "step": 7800
    },
    {
      "epoch": 0.06351452392246404,
      "grad_norm": 1.5135915279388428,
      "learning_rate": 4.936493515890691e-05,
      "loss": 0.0289,
      "step": 7900
    },
    {
      "epoch": 0.06431850523793826,
      "grad_norm": 3.084144353866577,
      "learning_rate": 4.935689534575217e-05,
      "loss": 0.0247,
      "step": 8000
    },
    {
      "epoch": 0.06431850523793826,
      "eval_loss": 0.025551412254571915,
      "eval_mse": 0.025551410391926765,
      "eval_runtime": 762.5739,
      "eval_samples_per_second": 142.756,
      "eval_steps_per_second": 17.845,
      "step": 8000
    },
    {
      "epoch": 0.0651224865534125,
      "grad_norm": 1.063732385635376,
      "learning_rate": 4.9348855532597425e-05,
      "loss": 0.0255,
      "step": 8100
    },
    {
      "epoch": 0.06592646786888673,
      "grad_norm": 1.9925236701965332,
      "learning_rate": 4.934081571944268e-05,
      "loss": 0.032,
      "step": 8200
    },
    {
      "epoch": 0.06673044918436095,
      "grad_norm": 4.3526153564453125,
      "learning_rate": 4.9332775906287945e-05,
      "loss": 0.03,
      "step": 8300
    },
    {
      "epoch": 0.06753443049983518,
      "grad_norm": 2.0841917991638184,
      "learning_rate": 4.93247360931332e-05,
      "loss": 0.0254,
      "step": 8400
    },
    {
      "epoch": 0.06833841181530942,
      "grad_norm": 0.46507683396339417,
      "learning_rate": 4.931669627997846e-05,
      "loss": 0.027,
      "step": 8500
    },
    {
      "epoch": 0.06914239313078364,
      "grad_norm": 0.8214919567108154,
      "learning_rate": 4.9308656466823714e-05,
      "loss": 0.0258,
      "step": 8600
    },
    {
      "epoch": 0.06994637444625787,
      "grad_norm": 3.0919787883758545,
      "learning_rate": 4.930061665366897e-05,
      "loss": 0.0261,
      "step": 8700
    },
    {
      "epoch": 0.0707503557617321,
      "grad_norm": 1.6666858196258545,
      "learning_rate": 4.9292576840514226e-05,
      "loss": 0.0308,
      "step": 8800
    },
    {
      "epoch": 0.07155433707720632,
      "grad_norm": 1.5313661098480225,
      "learning_rate": 4.928453702735948e-05,
      "loss": 0.0258,
      "step": 8900
    },
    {
      "epoch": 0.07235831839268056,
      "grad_norm": 3.915860652923584,
      "learning_rate": 4.927649721420474e-05,
      "loss": 0.0262,
      "step": 9000
    },
    {
      "epoch": 0.07235831839268056,
      "eval_loss": 0.019851762801408768,
      "eval_mse": 0.019851764664053917,
      "eval_runtime": 761.8575,
      "eval_samples_per_second": 142.89,
      "eval_steps_per_second": 17.862,
      "step": 9000
    },
    {
      "epoch": 0.07316229970815478,
      "grad_norm": 0.7273371815681458,
      "learning_rate": 4.926845740105e-05,
      "loss": 0.0296,
      "step": 9100
    },
    {
      "epoch": 0.07396628102362901,
      "grad_norm": 1.9840567111968994,
      "learning_rate": 4.926041758789526e-05,
      "loss": 0.0274,
      "step": 9200
    },
    {
      "epoch": 0.07477026233910324,
      "grad_norm": 2.807697296142578,
      "learning_rate": 4.9252377774740515e-05,
      "loss": 0.0262,
      "step": 9300
    },
    {
      "epoch": 0.07557424365457746,
      "grad_norm": 2.6484248638153076,
      "learning_rate": 4.924433796158577e-05,
      "loss": 0.022,
      "step": 9400
    },
    {
      "epoch": 0.0763782249700517,
      "grad_norm": 11.454380989074707,
      "learning_rate": 4.9236298148431034e-05,
      "loss": 0.0229,
      "step": 9500
    },
    {
      "epoch": 0.07718220628552593,
      "grad_norm": 0.6047989130020142,
      "learning_rate": 4.922825833527629e-05,
      "loss": 0.0324,
      "step": 9600
    },
    {
      "epoch": 0.07798618760100015,
      "grad_norm": 0.6321895718574524,
      "learning_rate": 4.922021852212155e-05,
      "loss": 0.0249,
      "step": 9700
    },
    {
      "epoch": 0.07879016891647438,
      "grad_norm": 1.6062926054000854,
      "learning_rate": 4.92121787089668e-05,
      "loss": 0.0293,
      "step": 9800
    },
    {
      "epoch": 0.07959415023194862,
      "grad_norm": 2.268651008605957,
      "learning_rate": 4.9204138895812066e-05,
      "loss": 0.0312,
      "step": 9900
    },
    {
      "epoch": 0.08039813154742284,
      "grad_norm": 3.129164934158325,
      "learning_rate": 4.919609908265732e-05,
      "loss": 0.0254,
      "step": 10000
    },
    {
      "epoch": 0.08039813154742284,
      "eval_loss": 0.03605079650878906,
      "eval_mse": 0.036050792783498764,
      "eval_runtime": 762.4734,
      "eval_samples_per_second": 142.775,
      "eval_steps_per_second": 17.847,
      "step": 10000
    },
    {
      "epoch": 0.08120211286289707,
      "grad_norm": 0.7876251339912415,
      "learning_rate": 4.918805926950258e-05,
      "loss": 0.0252,
      "step": 10100
    },
    {
      "epoch": 0.08200609417837129,
      "grad_norm": 3.3475279808044434,
      "learning_rate": 4.9180019456347835e-05,
      "loss": 0.0197,
      "step": 10200
    },
    {
      "epoch": 0.08281007549384552,
      "grad_norm": 1.050866723060608,
      "learning_rate": 4.917197964319309e-05,
      "loss": 0.0291,
      "step": 10300
    },
    {
      "epoch": 0.08361405680931976,
      "grad_norm": 1.0928895473480225,
      "learning_rate": 4.9163939830038355e-05,
      "loss": 0.03,
      "step": 10400
    },
    {
      "epoch": 0.08441803812479398,
      "grad_norm": 1.7837255001068115,
      "learning_rate": 4.915590001688361e-05,
      "loss": 0.03,
      "step": 10500
    },
    {
      "epoch": 0.0852220194402682,
      "grad_norm": 1.9709067344665527,
      "learning_rate": 4.914786020372887e-05,
      "loss": 0.0291,
      "step": 10600
    },
    {
      "epoch": 0.08602600075574243,
      "grad_norm": 0.41082727909088135,
      "learning_rate": 4.9139820390574124e-05,
      "loss": 0.0259,
      "step": 10700
    },
    {
      "epoch": 0.08682998207121667,
      "grad_norm": 2.9170289039611816,
      "learning_rate": 4.913178057741939e-05,
      "loss": 0.0246,
      "step": 10800
    },
    {
      "epoch": 0.0876339633866909,
      "grad_norm": 1.7194339036941528,
      "learning_rate": 4.912374076426464e-05,
      "loss": 0.0252,
      "step": 10900
    },
    {
      "epoch": 0.08843794470216512,
      "grad_norm": 0.6813889145851135,
      "learning_rate": 4.91157009511099e-05,
      "loss": 0.0243,
      "step": 11000
    },
    {
      "epoch": 0.08843794470216512,
      "eval_loss": 0.026725469157099724,
      "eval_mse": 0.026725471019744873,
      "eval_runtime": 762.2818,
      "eval_samples_per_second": 142.811,
      "eval_steps_per_second": 17.852,
      "step": 11000
    },
    {
      "epoch": 0.08924192601763935,
      "grad_norm": 1.5228177309036255,
      "learning_rate": 4.9107661137955156e-05,
      "loss": 0.0248,
      "step": 11100
    },
    {
      "epoch": 0.09004590733311357,
      "grad_norm": 1.7046293020248413,
      "learning_rate": 4.909962132480042e-05,
      "loss": 0.0247,
      "step": 11200
    },
    {
      "epoch": 0.09084988864858781,
      "grad_norm": 1.1993180513381958,
      "learning_rate": 4.9091581511645675e-05,
      "loss": 0.0212,
      "step": 11300
    },
    {
      "epoch": 0.09165386996406204,
      "grad_norm": 2.080465793609619,
      "learning_rate": 4.908354169849093e-05,
      "loss": 0.0223,
      "step": 11400
    },
    {
      "epoch": 0.09245785127953626,
      "grad_norm": 0.7226548790931702,
      "learning_rate": 4.907550188533619e-05,
      "loss": 0.0267,
      "step": 11500
    },
    {
      "epoch": 0.09326183259501049,
      "grad_norm": 0.9813971519470215,
      "learning_rate": 4.9067462072181444e-05,
      "loss": 0.026,
      "step": 11600
    },
    {
      "epoch": 0.09406581391048471,
      "grad_norm": 0.5562260746955872,
      "learning_rate": 4.905942225902671e-05,
      "loss": 0.0323,
      "step": 11700
    },
    {
      "epoch": 0.09486979522595895,
      "grad_norm": 0.9566439986228943,
      "learning_rate": 4.9051382445871964e-05,
      "loss": 0.0334,
      "step": 11800
    },
    {
      "epoch": 0.09567377654143318,
      "grad_norm": 4.052186965942383,
      "learning_rate": 4.904334263271722e-05,
      "loss": 0.0315,
      "step": 11900
    },
    {
      "epoch": 0.0964777578569074,
      "grad_norm": 3.285330057144165,
      "learning_rate": 4.9035302819562476e-05,
      "loss": 0.0263,
      "step": 12000
    },
    {
      "epoch": 0.0964777578569074,
      "eval_loss": 0.05388762429356575,
      "eval_mse": 0.05388762429356575,
      "eval_runtime": 762.8022,
      "eval_samples_per_second": 142.713,
      "eval_steps_per_second": 17.839,
      "step": 12000
    },
    {
      "epoch": 0.09728173917238163,
      "grad_norm": 1.5412055253982544,
      "learning_rate": 4.902726300640773e-05,
      "loss": 0.0241,
      "step": 12100
    },
    {
      "epoch": 0.09808572048785587,
      "grad_norm": 4.182709217071533,
      "learning_rate": 4.901922319325299e-05,
      "loss": 0.0229,
      "step": 12200
    },
    {
      "epoch": 0.0988897018033301,
      "grad_norm": 1.7518750429153442,
      "learning_rate": 4.9011183380098245e-05,
      "loss": 0.0207,
      "step": 12300
    },
    {
      "epoch": 0.09969368311880432,
      "grad_norm": 5.7575459480285645,
      "learning_rate": 4.90031435669435e-05,
      "loss": 0.0292,
      "step": 12400
    },
    {
      "epoch": 0.10049766443427854,
      "grad_norm": 2.4127049446105957,
      "learning_rate": 4.8995103753788765e-05,
      "loss": 0.0217,
      "step": 12500
    },
    {
      "epoch": 0.10130164574975277,
      "grad_norm": 1.7083197832107544,
      "learning_rate": 4.898706394063402e-05,
      "loss": 0.0238,
      "step": 12600
    },
    {
      "epoch": 0.10210562706522701,
      "grad_norm": 1.2597784996032715,
      "learning_rate": 4.897902412747928e-05,
      "loss": 0.0273,
      "step": 12700
    },
    {
      "epoch": 0.10290960838070123,
      "grad_norm": 1.5421723127365112,
      "learning_rate": 4.8970984314324534e-05,
      "loss": 0.0215,
      "step": 12800
    },
    {
      "epoch": 0.10371358969617546,
      "grad_norm": 1.896233081817627,
      "learning_rate": 4.89629445011698e-05,
      "loss": 0.0287,
      "step": 12900
    },
    {
      "epoch": 0.10451757101164968,
      "grad_norm": 9.34687614440918,
      "learning_rate": 4.895490468801505e-05,
      "loss": 0.0195,
      "step": 13000
    },
    {
      "epoch": 0.10451757101164968,
      "eval_loss": 0.030981862917542458,
      "eval_mse": 0.030981862917542458,
      "eval_runtime": 762.2683,
      "eval_samples_per_second": 142.813,
      "eval_steps_per_second": 17.852,
      "step": 13000
    },
    {
      "epoch": 0.10532155232712392,
      "grad_norm": 2.6071910858154297,
      "learning_rate": 4.894686487486031e-05,
      "loss": 0.0208,
      "step": 13100
    },
    {
      "epoch": 0.10612553364259815,
      "grad_norm": 1.9332094192504883,
      "learning_rate": 4.8938825061705566e-05,
      "loss": 0.0219,
      "step": 13200
    },
    {
      "epoch": 0.10692951495807237,
      "grad_norm": 2.5958797931671143,
      "learning_rate": 4.893078524855083e-05,
      "loss": 0.0219,
      "step": 13300
    },
    {
      "epoch": 0.1077334962735466,
      "grad_norm": 0.657101571559906,
      "learning_rate": 4.8922745435396085e-05,
      "loss": 0.0207,
      "step": 13400
    },
    {
      "epoch": 0.10853747758902083,
      "grad_norm": 1.79322350025177,
      "learning_rate": 4.891470562224134e-05,
      "loss": 0.0176,
      "step": 13500
    },
    {
      "epoch": 0.10934145890449506,
      "grad_norm": 0.7588464021682739,
      "learning_rate": 4.89066658090866e-05,
      "loss": 0.0272,
      "step": 13600
    },
    {
      "epoch": 0.11014544021996929,
      "grad_norm": 1.4400298595428467,
      "learning_rate": 4.8898625995931854e-05,
      "loss": 0.0286,
      "step": 13700
    },
    {
      "epoch": 0.11094942153544352,
      "grad_norm": 1.7838300466537476,
      "learning_rate": 4.889058618277712e-05,
      "loss": 0.0239,
      "step": 13800
    },
    {
      "epoch": 0.11175340285091774,
      "grad_norm": 3.227803945541382,
      "learning_rate": 4.8882546369622373e-05,
      "loss": 0.023,
      "step": 13900
    },
    {
      "epoch": 0.11255738416639198,
      "grad_norm": 1.5731027126312256,
      "learning_rate": 4.887450655646763e-05,
      "loss": 0.0201,
      "step": 14000
    },
    {
      "epoch": 0.11255738416639198,
      "eval_loss": 0.02236536704003811,
      "eval_mse": 0.02236536704003811,
      "eval_runtime": 762.7381,
      "eval_samples_per_second": 142.725,
      "eval_steps_per_second": 17.841,
      "step": 14000
    },
    {
      "epoch": 0.1133613654818662,
      "grad_norm": 3.84104061126709,
      "learning_rate": 4.8866466743312886e-05,
      "loss": 0.0215,
      "step": 14100
    },
    {
      "epoch": 0.11416534679734043,
      "grad_norm": 1.6154658794403076,
      "learning_rate": 4.885842693015815e-05,
      "loss": 0.0238,
      "step": 14200
    },
    {
      "epoch": 0.11496932811281466,
      "grad_norm": 4.875749588012695,
      "learning_rate": 4.8850387117003406e-05,
      "loss": 0.0216,
      "step": 14300
    },
    {
      "epoch": 0.11577330942828888,
      "grad_norm": 1.5923426151275635,
      "learning_rate": 4.884234730384866e-05,
      "loss": 0.0202,
      "step": 14400
    },
    {
      "epoch": 0.11657729074376312,
      "grad_norm": 2.118435859680176,
      "learning_rate": 4.883430749069392e-05,
      "loss": 0.0252,
      "step": 14500
    },
    {
      "epoch": 0.11738127205923735,
      "grad_norm": 1.7669155597686768,
      "learning_rate": 4.882626767753918e-05,
      "loss": 0.0245,
      "step": 14600
    },
    {
      "epoch": 0.11818525337471157,
      "grad_norm": 0.7539511322975159,
      "learning_rate": 4.881822786438444e-05,
      "loss": 0.0224,
      "step": 14700
    },
    {
      "epoch": 0.1189892346901858,
      "grad_norm": 3.4707834720611572,
      "learning_rate": 4.8810188051229694e-05,
      "loss": 0.0257,
      "step": 14800
    },
    {
      "epoch": 0.11979321600566002,
      "grad_norm": 0.5239623785018921,
      "learning_rate": 4.880214823807495e-05,
      "loss": 0.0198,
      "step": 14900
    },
    {
      "epoch": 0.12059719732113426,
      "grad_norm": 0.8283553123474121,
      "learning_rate": 4.8794108424920207e-05,
      "loss": 0.0283,
      "step": 15000
    },
    {
      "epoch": 0.12059719732113426,
      "eval_loss": 0.017234506085515022,
      "eval_mse": 0.017234506085515022,
      "eval_runtime": 763.84,
      "eval_samples_per_second": 142.519,
      "eval_steps_per_second": 17.815,
      "step": 15000
    }
  ],
  "logging_steps": 100,
  "max_steps": 621905,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.157304315904e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
